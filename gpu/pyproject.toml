[tool.poetry]
name = "gpu"
version = "0.1.0"
description = ""
authors = ["Your Name <you@example.com>"]
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.11"
torch = {version = "2.3.0+cu121", source = "pytorch"}
torchvision = {version = "0.18.0+cu121", source = "pytorch"}
torchaudio = {version = "2.3.0+cu121", source = "pytorch"}
torch_geometric = { version = "2.5.3", extras = ["graphgym"] }
torch_scatter = {version = "2.1.2", source = "torch_geo_opt"}
torch_sparse = {version = "0.6.18", source = "torch_geo_opt"}
torch_cluster = {version = "1.6.3", source = "torch_geo_opt"}
torch_spline_conv = {version = "1.2.2", source = "torch_geo_opt"}
pyg_lib = {version = "0.4.0", source = "torch_geo_opt"}
llama-cpp-python = {version = "0.2.77", source = "llama-cpp"}
bertopic = "^0.16.2"
celery = "^5.4.0"
redis = { version = "^5.0.5", extras = ["hiredis"] } 
gevent = "^23.9.1"
huggingface-hub = "^0.23.3"

[[tool.poetry.source]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cu121"
priority = "explicit"

[[tool.poetry.source]]
name = "torch_geo_opt"
url = "https://data.pyg.org/whl/torch-2.3.0+cu121.html"
priority = "explicit"

[[tool.poetry.source]]
name = "llama-cpp"
url = "https://abetlen.github.io/llama-cpp-python/whl/cu121"
priority = "explicit"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
